# Basic info
replicaCount: "__REQUIRED__"
secretsRef: "__REQUIRED__"
image:
  repository: registry.hub.docker.com/datamountaineer/kafka-connect-influx-sink
  tag: 0.3.0
  pullPolicy: IfNotPresent

# Resource management
resources:
  limits:
    memory: 512Mi
  requests:
    memory: 256Mi
javaHeap: 256M

# Monitoring
monitoring:
  pipeline: "__REQUIRED__"
  enabled: true
  port: 9102
  path: "/metrics"

# SSL/TLS options can be enabled, some connectors provide SSL support, others the newer TLS
# Set the corresponding value type to true. For SSL persistent volumes or hostPaths will be
# mounted under /connector-extra-config. Set the connectors ssl/tls option paths to be use this
# TLS is done via Secrets, create a secret for containing the certificates (base64 encoded) and
# create a secret for them, adding the name of the secret to the `secretsRef` other wise if using
# Eneco's Landscaper it will do this for you.

# SSL mount path on hosts, should be the base path of any ssl keystore/truststore paths
ssl:
  enabled: false
  # Path to the directory on the hosts
  path: /ssl

  # If persistent volumes should be used for ssl keystore/truststore paths
  persistentVolumes:
    enable: false
    existingClaim:

# TLS, for those connectors supporting TLS certificates rather than ssl key/truststores
# contents for mount take from config map
tls:
  enabled: false

## Avro schemas, for those connectors, MQTT and JMS source that support Avro converters we
## need the schemas, so we'll mount as a ConfigMap. Set the key value pairs, filename and data
## matching the value option avroSchema. Key is the file name, value is the avro schema contents
#avroSchemaFiles:
#  schema_file_name:  ""

applicationId: "__REQUIRED__"
topics: "__REQUIRED__"
tasksMax: 3


connectorClass: com.datamountaineer.streamreactor.connect.influx.InfluxSinkConnector
# db The database to store the values to. type: STRING importance: HIGH
db: "__REQUIRED__"

# maxRetries The maximum number of times to try the write again. type: INT importance: MEDIUM
maxRetries: 20

# password The password for the influxdb user. type: PASSWORD importance: HIGH
password: "__REQUIRED__"

# url The InfluxDB database url. type: STRING importance: HIGH
url: "__REQUIRED__"

# enabled Enables the output for how many records have been processed by the connector type: BOOLEAN importance: MEDIUM
enabled: false

# retryInterval The time in milliseconds between retries. type: INT importance: MEDIUM
retryInterval: 60000

# errorPolicy Specifies the action to be taken if an error occurs while inserting the data.
# There are two available options:
# NOOP - the error is swallowed
# THROW - the error is allowed to propagate.
# RETRY - The exception causes the Connect framework to retry the message. The number of retries is based on
# The error will be logged automatically type: STRING importance: HIGH
errorPolicy: THROW

# consistencyLevel Specifies the write consistency. If any write operations do not meet the configured consistency guarantees, an error will occur and the data will not be indexed. The default consistency-level is ALL. type: STRING importance: MEDIUM
consistencyLevel: ALL

# username The user to connect to the influx database type: STRING importance: HIGH
username: "__REQUIRED__"

# retentionPolicy 
# Determines how long InfluxDB keeps the data - the options for specifying the duration of the retention policy are listed below.
# Note that the minimum retention period is one hour.
# DURATION determines how long InfluxDB keeps the data - the options for specifying the duration of the retention policy are listed below. Note that the minimum retention period is one hour.
# m minutes
# h hours
# d days
# w weeks
# INF infinite
# 
# Default retention is `autogen` from 1.0 onwards or `default` for any previous version
#      type: STRING importance: HIGH
retentionPolicy: autogen

# kcql KCQL expression describing field selection and target measurements. type: STRING importance: HIGH
kcql: "__REQUIRED__"

topics: __REQUIRED__
